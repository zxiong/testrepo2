---
apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  annotations:
    build.appstudio.openshift.io/repo: https://github.com/zxiong/testrepo1?rev={{revision}}
    build.appstudio.redhat.com/commit_sha: '{{revision}}'
    build.appstudio.redhat.com/pull_request_number: '{{pull_request_number}}'
    build.appstudio.redhat.com/target_branch: '{{target_branch}}'
    pipelinesascode.tekton.dev/cancel-in-progress: "true"
    pipelinesascode.tekton.dev/max-keep-runs: "3"
    pipelinesascode.tekton.dev/on-cel-expression: event == "pull_request" && target_branch
      == "main"
  creationTimestamp: null
  labels:
    appstudio.openshift.io/application: test-app1
    appstudio.openshift.io/component: test-fbc-fips1
    pipelines.appstudio.openshift.io/type: build
  name: testrepo-fbc-test1-on-pull-request
spec:
  timeouts:
    pipeline: "4h"
  params:
  - name: git-url
    value: '{{source_url}}'
  - name: revision
    value: '{{revision}}'
  - name: output-image
    value: quay.io/redhat-user-workloads/zxiong-tenant/testrepo-2-test-tasl-upgrade:{{revision}}
  - name: image-expires-after
    value: 5d
  - name: dockerfile
    value: Dockerfile
  - name: NUM_BUCKETS
    value: "5"
  - name: MAX_PARALLEL
    value: "2"
  - name: ENABLE_LOAD_BALANCING
    value: "true"
  - name: PARALLEL_FETCH_LIMIT
    value: "5" 
  pipelineSpec:
    params:
    - description: Source Repository URL
      name: git-url
      type: string
    - default: ""
      description: Revision of the Source Repository
      name: revision
      type: string
    - description: Fully Qualified Output Image
      name: output-image
      type: string
    - default: .
      description: Path to the source code of an application's component from where
        to build image.
      name: path-context
      type: string
    - default: Dockerfile
      description: Path to the Dockerfile inside the context specified by parameter
        path-context
      name: dockerfile
      type: string
    - default: "false"
      description: Force rebuild image
      name: rebuild
      type: string
    - default: "false"
      description: Skip checks against built image
      name: skip-checks
      type: string
    - default: "false"
      description: Execute the build with network isolation
      name: hermetic
      type: string
    - default: ""
      description: Build dependencies to be prefetched
      name: prefetch-input
      type: string
    - default: ""
      description: Image tag expiration time, time values could be something like
        1h, 2d, 3w for hours, days, and weeks, respectively.
      name: image-expires-after
      type: string
    - default: "false"
      description: Build a source image.
      name: build-source-image
      type: string
    - default: "false"
      description: Add built image into an OCI image index
      name: build-image-index
      type: string
    - description: Number of parallel TaskRuns (buckets) to create
      name: NUM_BUCKETS
      type: string
      default: "2"
    - description: Maximum number of images to check in parallel
      name: MAX_PARALLEL
      type: string
      default: "5"
    - description: Enable size-based load balancing across buckets
      name: ENABLE_LOAD_BALANCING
      type: string
      default: "true"
    - description: Number of parallel skopeo processes when fetching image sizes
      name: PARALLEL_FETCH_LIMIT
      type: string
      default: "5"
    tasks:
    #
    # TASK 1: Extract images, create OCI artifact, and generate bucket indices
    #
    - name: prepare-images-and-buckets
      timeout: "5m"
      params:
      - name: NUM_BUCKETS
        value: $(params.NUM_BUCKETS)
      - name: ENABLE_LOAD_BALANCING
        value: $(params.ENABLE_LOAD_BALANCING)
      - name: PARALLEL_FETCH_LIMIT
        value: $(params.PARALLEL_FETCH_LIMIT)
      taskSpec:
        params:
          - name: NUM_BUCKETS
            type: string
          - name: ENABLE_LOAD_BALANCING
            type: string
          - name: PARALLEL_FETCH_LIMIT
            type: string
        results:
          - name: IMAGES_ARTIFACT
            type: string
            description: OCI reference to images artifact
          - name: BUCKET_INDICES
            type: array
            description: Array of bucket indices for matrix expansion
        volumes:
          - name: workdir
            emptyDir: {}
        stepTemplate:
          volumeMounts:
            - name: workdir
              mountPath: /var/workdir  
        steps:
   - name: prepare-images-and-buckets
      timeout: "5m"
      params:
      - name: NUM_BUCKETS
        value: $(params.NUM_BUCKETS)
      - name: ENABLE_LOAD_BALANCING
        value: $(params.ENABLE_LOAD_BALANCING)
      - name: PARALLEL_FETCH_LIMIT
        value: $(params.PARALLEL_FETCH_LIMIT)
      taskSpec:
        params:
          - name: NUM_BUCKETS
            type: string
          - name: ENABLE_LOAD_BALANCING
            type: string
          - name: PARALLEL_FETCH_LIMIT
            type: string
        results:
          - name: IMAGES_ARTIFACT
            type: string
            description: OCI reference to images artifact
          - name: BUCKET_INDICES
            type: array
            description: Array of bucket indices for matrix expansion
        volumes:
          - name: workdir
            emptyDir: {}
        stepTemplate:
          volumeMounts:
            - name: workdir
              mountPath: /var/workdir
        steps:
          # Step 1: Extract images and split into bucket files
          - name: extract-and-split-images
            image: quay.io/konflux-ci/konflux-test:v1.4.41@sha256:afea44d83043be7f528ec2cacaeb0c3b69cdafdd86a1b930957def38400f8a6c
            env:
              - name: NUM_BUCKETS
                value: $(params.NUM_BUCKETS)
              - name: ENABLE_LOAD_BALANCING
                value: $(params.ENABLE_LOAD_BALANCING)
              - name: PARALLEL_FETCH_LIMIT
                value: $(params.PARALLEL_FETCH_LIMIT)
            script: |
              #!/usr/bin/env bash
              set -euo pipefail

              echo "Extracting images from FBC..."
              mkdir -p /var/workdir/artifact-data

              # Simulate extracting images (replace with real extraction)
              # In real case, this would be from fbc-extract-images-oci-ta
              all_images=(
                "registry.redhat.io/rhoai/odh-training-rocm62-torch25-py311-rhel9@sha256:e950fc961dd81bae356a5ae93cdd00c4b50799fef0ce742d92b3feeae08dcc40"
                "registry.redhat.io/rhoai/odh-training-rocm62-torch24-py311-rhel9@sha256:38568cb655ff565b32ce92a735b9e2ff802f86f08837c260a854d039954a8b54"
              )

              num_images=${#all_images[@]}
              num_buckets=${NUM_BUCKETS}

              echo "Extracted ${num_images} images"
              echo "Splitting into ${num_buckets} buckets..."

              # Adjust num_buckets if more buckets than images
              if [ "${num_buckets}" -gt "${num_images}" ]; then
                num_buckets=${num_images}
                echo "Adjusted buckets to match images: ${num_buckets}"
              fi

              # Initialize buckets (in-memory arrays)
              declare -a buckets
              for ((i=0; i<num_buckets; i++)); do
                buckets[$i]=""
              done

              # Apply load balancing if enabled
              if [[ "${ENABLE_LOAD_BALANCING}" == "true" ]]; then
                echo "Load balancing enabled: Fetching image sizes for balanced distribution..."
                echo "Fetching sizes in parallel (${PARALLEL_FETCH_LIMIT} concurrent processes)..."

                # Get image sizes in parallel
                declare -A image_sizes
                temp_sizes=$(mktemp)

                # Function to fetch single image size
                fetch_size() {
                  local img=$1
                  local size
                  # Sum all layer sizes from LayersData to get total image size
                  size=$(skopeo inspect "docker://${img}" 2>/dev/null | jq '[.LayersData[]?.Size // 0] | add // 0' || echo "0")
                  echo "${img}|${size}"
                }
                export -f fetch_size

                # Fetch sizes in parallel
                printf '%s\n' "${all_images[@]}" | xargs -P "${PARALLEL_FETCH_LIMIT}" -I {} bash -c 'fetch_size "$@"' _ {} > "${temp_sizes}"

                # Read results into associative array
                while IFS='|' read -r img size; do
                  image_sizes["$img"]=$size
                  echo "Image $img size: $size bytes"
                done < "${temp_sizes}"

                rm -f "${temp_sizes}"

                # Create array of image|size pairs
                image_list=()
                for img in "${all_images[@]}"; do
                  image_list+=("${img}|${image_sizes[$img]}")
                done

                # Sort by size (descending)
                readarray -t sorted_images < <(printf '%s\n' "${image_list[@]}" | sort -t'|' -k2 -rn)

                echo "Sorted images by size (largest first):"
                for item in "${sorted_images[@]}"; do
                  echo "  ${item}"
                done

                # Distribute using greedy algorithm (assign each image to lightest bucket)
                declare -A bucket_weights
                for ((i=0; i<num_buckets; i++)); do
                  bucket_weights[$i]=0
                done

                for item in "${sorted_images[@]}"; do
                  img="${item%%|*}"
                  size="${item##*|}"

                  # Find bucket with minimum weight
                  min_bucket=0
                  min_weight=${bucket_weights[0]}
                  for ((i=1; i<num_buckets; i++)); do
                    if [ "${bucket_weights[$i]}" -lt "${min_weight}" ]; then
                      min_weight=${bucket_weights[$i]}
                      min_bucket=$i
                    fi
                  done

                  # Add image to lightest bucket
                  if [ -n "${buckets[$min_bucket]}" ]; then
                    buckets[$min_bucket]="${buckets[$min_bucket]}"$'\n'"${img}"
                  else
                    buckets[$min_bucket]="${img}"
                  fi
                  bucket_weights[$min_bucket]=$((bucket_weights[$min_bucket] + size))
                  echo "Assigned $img (size: $size) to bucket $min_bucket (total weight: ${bucket_weights[$min_bucket]})"
                done

                echo ""
                echo "Load balanced bucket distribution:"
                for ((i=0; i<num_buckets; i++)); do
                  echo "Bucket $i weight: ${bucket_weights[$i]} bytes"
                done

              else
                echo "Load balancing disabled: Using round-robin distribution..."

                # Distribute images into buckets (round-robin)
                bucket_idx=0
                for img in "${all_images[@]}"; do
                  if [ -n "${buckets[$bucket_idx]}" ]; then
                    buckets[$bucket_idx]="${buckets[$bucket_idx]}"$'\n'"${img}"
                  else
                    buckets[$bucket_idx]="${img}"
                  fi
                  bucket_idx=$(( (bucket_idx + 1) % num_buckets ))
                done
              fi

              # Write buckets to files
              echo ""
              echo "Writing buckets to files..."
              for ((i=0; i<num_buckets; i++)); do
                bucket_file="/var/workdir/artifact-data/bucket-${i}.txt"
                echo "${buckets[$i]}" > "${bucket_file}"
                bucket_size=$(wc -l < "${bucket_file}")
                echo "Bucket ${i}: ${bucket_size} images"
              done

              echo "Split complete!"
              echo "Bucket files created:"
              ls -lh /var/workdir/artifact-data/

          # Step 2: Push as OCI trusted artifact
          - name: create-trusted-artifact
            image: quay.io/konflux-ci/build-trusted-artifacts:latest@sha256:aa601d847eafa87747894b770eff43b47cffe2cc39059bb345ee58b378473b8f
            args:
              - create
              - --store
              - $(params.output-image)-fips-images
              - $(results.IMAGES_ARTIFACT.path)=/var/workdir/artifact-data

          # Step 3: Generate bucket indices
          - name: generate-bucket-indices
            image: quay.io/konflux-ci/konflux-test:v1.4.41@sha256:afea44d83043be7f528ec2cacaeb0c3b69cdafdd86a1b930957def38400f8a6c
            env:
              - name: NUM_BUCKETS
                value: $(params.NUM_BUCKETS)
            script: |
              #!/usr/bin/env bash
              set -euo pipefail

              # The artifact reference was already written by build-trusted-artifacts
              # Just verify it exists
              if [ -f "$(results.IMAGES_ARTIFACT.path)" ]; then
                artifact_ref=$(cat "$(results.IMAGES_ARTIFACT.path)")
                echo "Trusted artifact created: ${artifact_ref}"
              else
                echo "ERROR: IMAGES_ARTIFACT result not found"
                exit 1
              fi

              # Generate bucket indices
              echo "Generating bucket indices..."
              num_buckets=${NUM_BUCKETS}

              indices_json="["
              for ((i=0; i<num_buckets; i++)); do
                if [ $i -gt 0 ]; then
                  indices_json+=","
                fi
                indices_json+="\"${i}\""
              done
              indices_json+="]"

              echo "Generated bucket indices: ${indices_json}"
              echo -n "${indices_json}" > "$(results.BUCKET_INDICES.path)"

    #
    # TASK 2: Matrix FIPS check - pulls artifact and processes bucket
    #
    - name: fips-check-buckets
      timeout: "4h"
      runAfter:
        - prepare-images-and-buckets
      params:
      - name: IMAGES_ARTIFACT
        value: "$(tasks.prepare-images-and-buckets.results.IMAGES_ARTIFACT)"
      - name: TARGET_OCP_VERSION
        value: ""
      - name: MAX_PARALLEL
        value: $(params.MAX_PARALLEL)
      matrix:
        params:
          - name: BUCKET_INDEX
            value: $(tasks.prepare-images-and-buckets.results.BUCKET_INDICES[*])
      taskSpec:
        params:
          - name: BUCKET_INDEX
            type: string
          - name: IMAGES_ARTIFACT
            type: string
          - name: TARGET_OCP_VERSION
            type: string
          - name: MAX_PARALLEL
            type: string
        volumes:
          - name: workdir
            emptyDir: {}
        stepTemplate:
          volumeMounts:
            - name: workdir
              mountPath: /var/workdir
        steps:
          # Step 1: Create directory for artifact extraction
          - name: prepare-workdir
            image: quay.io/konflux-ci/konflux-test:v1.4.41@sha256:afea44d83043be7f528ec2cacaeb0c3b69cdafdd86a1b930957def38400f8a6c
            script: |
              #!/usr/bin/env bash
              set -euo pipefail
              mkdir -p /var/workdir/artifact-data
              echo "Created /var/workdir/artifact-data directory"

          # Step 2: Pull the OCI artifact
          - name: use-trusted-artifact
            image: quay.io/konflux-ci/build-trusted-artifacts:latest@sha256:aa601d847eafa87747894b770eff43b47cffe2cc39059bb345ee58b378473b8f
            args:
              - use
              - $(params.IMAGES_ARTIFACT)=/var/workdir/artifact-data

          # Step 3: Read bucket file and prepare input files for FIPS check
          - name: prepare-bucket-images
            image: quay.io/konflux-ci/konflux-test:v1.4.41@sha256:afea44d83043be7f528ec2cacaeb0c3b69cdafdd86a1b930957def38400f8a6c
            env:
              - name: BUCKET_INDEX
                value: $(params.BUCKET_INDEX)
              - name: TARGET_OCP_VERSION
                value: $(params.TARGET_OCP_VERSION)
            script: |
              #!/usr/bin/env bash
              set -euo pipefail

              echo "=========================================="
              echo "FIPS Check - Bucket ${BUCKET_INDEX}"
              echo "=========================================="

              # Read bucket file directly
              bucket_file="/var/workdir/artifact-data/bucket-${BUCKET_INDEX}.txt"

              if [ ! -f "${bucket_file}" ]; then
                echo "ERROR: Bucket file not found at ${bucket_file}"
                echo "Available files:"
                ls -la /var/workdir/artifact-data/ || true
                exit 1
              fi

              # Read images from bucket file
              readarray -t bucket_images < "${bucket_file}"
              num_bucket_images=${#bucket_images[@]}

              echo "Bucket file: ${bucket_file}"
              echo "This bucket contains: ${num_bucket_images} images"

              # Write images to file for FIPS check stepaction
              mkdir -p /tekton/home
              printf '%s\n' "${bucket_images[@]}" > /tekton/home/unique_related_images.txt

              # Write target OCP version if provided
              if [ -n "${TARGET_OCP_VERSION}" ]; then
                echo -n "${TARGET_OCP_VERSION}" > /tekton/home/target_ocp_version.txt
                echo "Target OCP version: ${TARGET_OCP_VERSION}"
              fi

              echo "Prepared ${num_bucket_images} images for FIPS compliance check"
              echo "=========================================="

          # Step 4: Run FIPS operator check
          - name: fips-operator-check-step-action
            params:
              - name: MAX_PARALLEL
                value: $(params.MAX_PARALLEL)
            computeResources:
              limits:
                cpu: "2"
                memory: 4Gi
              requests:
                cpu: "2"
                memory: 4Gi
            ref:
              params:
                - name: url
                  value: https://github.com/konflux-ci/build-definitions
                - name: revision
                  value: ac78bc7b6ea4d34781a4cff44ae9647745e2e65d
                - name: pathInRepo
                  value: stepactions/fips-operator-check-step-action/0.1/fips-operator-check-step-action.yaml
              resolver: git
    workspaces:
    - name: git-auth
      optional: true
    - name: netrc
      optional: true
  taskRunTemplate:
    serviceAccountName: build-pipeline-testrepo-2-test-tasl-upgrade
  workspaces:
  - name: git-auth
    secret:
      secretName: '{{ git_auth_secret }}'
status: {}
